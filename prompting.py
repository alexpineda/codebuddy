import datetime
from openai import OpenAI
import os
from utils import log_trace
from tools.suggested_context_finder import SuggestedContextFinder

class PromptHandler:
    def __init__(self, trace_log_file, interval):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.trace_log_file = trace_log_file
        self.context_finder = SuggestedContextFinder()
        self.interval = interval

    def process_screenshot(self, base64_image, filename, active_window_title):
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": """
                        You are a screenshot analysis assistant.
                        You are part of an application that is purposed around aiding the user in their productivity and act as a short term memory.
                        The following is a screenshot of a series of screenshots of the user's screen taken in {self.interval} second intervals.
                        A screenshot will not be taken if the user is on the same screen they started this application on (command line console).
                        The response will be added cumulatively to an 'activity' log file where another assistant will read the log and respond to the user about their activity.
                        Feel free to use the context of the previous screenshots to help you describe the current screenshot.
                        Use any special encoding or formatting to aid in the process of describing the screenshot, including compression of repetitive text or repeating screenshots.
                        """
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": f"Screenshot of the user's screen taken at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}. The active window is: {active_window_title}"
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=2000
            )
            
            vision_response = response.choices[0].message.content
            log_trace(f"Saved screenshot: {filename}", self.trace_log_file)
            log_trace(f"Active window: {active_window_title}", self.trace_log_file)
            log_trace(vision_response, self.trace_log_file)
            return True
        except Exception as e:
            log_trace(f"Failed to send screenshot to vision model: {e}", self.trace_log_file)
            print(f"Failed to send screenshot to vision model: {e}")
            return False

    def handle_user_inquiry(self, user_input: str) -> str:
        try:
            # Get suggested context before forming the prompt
            # context = self.context_finder.get_suggested_context(self.trace_log_file)
            
            # # Add context to the prompt if confidence is high enough
            # context_prompt = ""
            # if context["confidence"] > 0.4:
            #     context_prompt = "\nRecent context:"
            #     if context["file_path"]:
            #         context_prompt += f"\nFile: {context['file_path']}"
            
            # print(f"Context: {context_prompt}")
            
            # Combine with existing prompt logic
            with open(self.trace_log_file, 'r') as f:
                log_content = f.read()
            
            log_trace(f"USER INQUIRY: {user_input}", self.trace_log_file)
            
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": """
                     You are an assistant that is purposed around aiding the user in their productivity and act as a short term memory.
                     Provide an appropriate response based on the given users activity log.
                     The activity log is generated by capturing screenshots of the users activity and using a vision model to write the log. 
                     The log may also contain previous responses from the user and you, assistant.
                     Screenshots are taken in {self.interval} second intervals, unless the user is on the same screen they started this application on (command line console).
                     Be positive. The user is working on something important. The user is trying to get things done and needs help.
                     Talk like a really smart engineer, quirky, super sharp, no bullshit, full of insights, helpful, to the point. We are pumped to be working togethor, can get annoyed with each other sometimes, and want to be efficient and make great products.
                     """},
                     {"role": "assistant", "content": f"Latest activity log: {log_content}. How can I help you?"},
                    {"role": "user", "content": user_input}
                ]
            )
            assistant_response = response.choices[0].message.content
            
            log_trace(f"ASSISTANT RESPONSE: {assistant_response}", self.trace_log_file)
            return assistant_response 
        except Exception as e:
            log_trace(f"Failed to handle user inquiry: {e}", self.trace_log_file)
            print(f"Failed to handle user inquiry: {e}")
            return "Sorry, I couldn't process your request." 